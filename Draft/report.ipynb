{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "STA 663 Final Project\n",
    "<br>\n",
    "Author: Yiling Liu, Lanqiu Yao\n",
    "\n",
    "master project 恶心死人了，之后再多写一个字都好煎熬 TUT"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<p style=\"text-align: center;\">\n",
    "<span style=\"color: ; font-family: Babas; font-size: 2em;\">Hierarchical Topic models and </span>\n",
    "</p> \n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "<span style=\"color: ; font-family: Babas; font-size: 2em;\">the Nested Chinese Restaurant Process</span>\n",
    "</p> \n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 1. Introduction"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 2. Chinese Restaurant Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The Chinese Restaurant Process (CRP) is a distribuition on partitions of integers. Imagine there are M customers in a Chinese restaurant with infinte tables. The first customer sit in the first table. The following customers have two kinds of choices:\n",
    "\n",
    "+ Sit in the table that some one alse is already there \n",
    "+ Sit in a new table\n",
    "\n",
    "These two choices have probabilities that depend on the previosu customers at the tables. \n",
    "<br>\n",
    "Specifically, for the $m$th customer, the probability to sit in a table is:\n",
    "+ p(occupied table i| previous customers) = $\\frac{m_i}{\\gamma+m-1}$\n",
    "+ p(next unoccupied table| previous customers) = $\\frac{\\gamma}{\\gamma+m-1}$,\n",
    "\n",
    "where $m_i$ represnets the number of previous customers at the table $i$; $\\gamma$ is a parameter.\n",
    "\n",
    "If we have M customers, the CRP will give us a partion of M customers, which has the same structure as a Dirichlet process. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![3](3.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 2.1 Nested Chinese Restaurant Process"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CRP establishes a one-to-one relationship between tables and mixture components. A hierarchical version of CRP was also developed to model one-to-many\n",
    "\n",
    "The nCRP is very similar with CRP except for its hieracrchical structure. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "We can see an example in the following plot.\n",
    "![1](1.png)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "###  2.2 A very simple version of CRP in Python"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The function for chinese restaurant process (CRP):\n",
    "\n",
    "**Input**\n",
    "+ N is the number of customs\n",
    "+ alpha is the $\\alpha$ parameter\n",
    "\n",
    "**Output**\n",
    "+ The number of custom in each table \n",
    "+ The probability of sitting in each table"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRP(alpha,N):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------\n",
    "    Funcion: Chinese Restaurant Process\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    alpha: concentration parameter \n",
    "    N: the number of customers\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    tables: number of customers at each table\n",
    "    p: the probability for customers to sit in each table\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    # initial\n",
    "    # N: total number of people \n",
    "    # alpha: the alpha parameter\n",
    "    tables = np.zeros(N)  # table's number of customer \n",
    "    tables[0] = 1         # at first, every table is empty\n",
    "    if N==1:\n",
    "        tables=np.array(1)\n",
    "        p=[1]\n",
    "    if N>1:\n",
    "        for i in range(2,N+1):\n",
    "            p_old=tables/(alpha+i-1) # the probability of sitting in a table with other people   \n",
    "            p_old=p_old[p_old>0] \n",
    "            p_new=alpha/(alpha+i-1)      # the probability of sitting in a new table\n",
    "            n_temp=len(p_old)+1\n",
    "            p=list(p_old)+[p_new]\n",
    "            num=np.random.choice(n_temp,p=p) # generate the table number based on the probabilities\n",
    "            tables[num]=tables[num]+1\n",
    "        tables=tables[tables>0]\n",
    "    return(tables,p)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 78,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRP_next(alpha,topic):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------\n",
    "    Funcion: Chinese Restaurant Process\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    alpha: concentration parameter \n",
    "    topic: the exist tables \n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    p: the probability for a new customers to sit in each of the tables\n",
    "    \"\"\"\n",
    "    import numpy as np\n",
    "    N=len(topic) # number of tables\n",
    "    word_list=[] # total customers\n",
    "    for t in topic:\n",
    "        word_list=word_list+t\n",
    "    m=len(word_list) # customers' number\n",
    "    \n",
    "    tables = np.array([len(x) for x in topic])  # tables with their customers\n",
    "    p_old=tables/(alpha+m) # the probability of sitting in a table with other people   \n",
    "    p_new=alpha/(alpha+m)      # the probability of sitting in a new table\n",
    "    p=list(p_old)+[p_new]  # the last probability is the probability to sit in a new table \n",
    "    return(p)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(array([45., 43.,  1.,  2.,  9.]), [0.44, 0.43, 0.01, 0.02, 0.09, 0.01])"
      ]
     },
     "execution_count": 27,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "CRP(1,100)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 330,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0.6666666666666666, 0.2222222222222222, 0.1111111111111111]"
      ]
     },
     "execution_count": 330,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "topic=[['a', 'ggtfdg', 'dsgfgfd', 'ds', 'ds', 'yhhr'], ['123', '66']]\n",
    "CRP_next(1,topic)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 3. A hierarchical topic model\n",
    "\n",
    "<span style=\"color:red\"> need more descriptions.</span>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 3.1 A topic model \n",
    "\n",
    "\n",
    "Generation of a document:\n",
    "1. Choose a $K$-vector $\\theta$ of topic proportions from a distribution $p(\\theta|\\alpha)$ \n",
    "2. Repeated sample words from the mixture distriubtion $p(\\omega|\\theta)$ for the chosen value of $\\theta$\n",
    "\n",
    "Besides, when the $p(\\theta|\\alpha)$ is chosen to be a Dirichlet distribution, these processes are identified as a latent Dirichlet allocation model (LDA)\n",
    "\n",
    "### 3.2 A hierarchical topic model \n",
    "\n",
    "Back to the hierarchical topic model, which is very simliar with previous one but added a hierarchical structure. For a hierarchial topic model with L-levels, we can imagine it as a L-level tree and each node presents a topic.\n",
    "\n",
    "Generation of a document:\n",
    "1. Choose a path from the root to a leaf\n",
    "2. Choose the topic proportions $\\theta$ from a L-dimension Dirichlet\n",
    "3. Generated the words in the document for m a mixture of the topics along the path from the root to leaf, wiht mixing proportions $\\theta$\n",
    "\n",
    "This generation of document is very simliar with previous one except the mixing proportion $\\theta$ is from a hierarchical structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "![2](2.png)\n",
    "\n",
    "The graph represnets the hierarchical LDA (hLDA) model. The hLDA has a prior from nCRP. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "just to show our understanding of the project \n",
    "\n",
    "+ $\\omega$\n",
    "+ $z$: a multinomial variable\n",
    "+ $\\beta$: a parameter\n",
    "+ $\\theta$: a $K-$dimensional vector\n",
    "\n",
    "document specific mixture distribution: $p(\\omega|\\theta)=\\sum_{i=1}^{K} \\theta_i p(\\omega| z=i, \\beta+i)$\n",
    "\n",
    "$p(\\theta|\\alpha)$ Dirichlet distribution\n",
    "\n",
    "+ $\\alpha$: a corpus-level parameter \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 4. Approximate inference by Gibbs sampling"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.1 Introduction to Gibbs sampling\n",
    "\n",
    "<span style=\"color:red\"> add some introduction about gibbs sampling?.</span>\n",
    "\n",
    "\n",
    "### 4.2 Gibbs sampling for the hLDA model\n",
    "\n",
    "**The variables that are needed to be sampled are:**\n",
    "\n",
    "1. $w_{m,n}$: the $n$th word in the $m$th document (Important note: these are the only observed variables in the model)\n",
    "2. $c_{m,l}$: the restaurant (node), the $l$th topic in the $m$th document\n",
    "3. $z_{m,n}$: the assignment of the $n$th word in the $m$th document to one of the $L$ topics\n",
    "4. There are also some variables needed in the model, but they are not needed to be sampled\n",
    "\n",
    "After illustrate the variables in the model, we also need to know the order and the methods of the sampling. We can apply the sampling methods into two steps: \n",
    "1. sample the $z_{m,n}$ variale by using LDA+CRP\n",
    "2. sample the $c_{m,l}$ based on the first step (given the LDA hidden variables). \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* To be more specific:\n",
    "\n",
    "### 4.2.1 Sample $z_{m,n}$\n",
    "\n",
    "The $z_{m,n}$ is sampled under LDA model based on the method in paper:\n",
    "\n",
    "<p style=\"text-align: center;\">\n",
    "*A probabilistic approach to semantic representation*\n",
    "</p>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The distribution of any word "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {},
   "outputs": [],
   "source": [
    "def Z(corpus, T, alpha, beta):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------\n",
    "    Funcion:  sample zmn under LDA model\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    corpus: the total corpus, a list of documents, that is, a list of lists\n",
    "    T: the number of topics\n",
    "    alpha, beta: parameters\n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    topic: the word list in each topic\n",
    "    topic_num: the length of each topic\n",
    "    \"\"\"\n",
    "    \n",
    "    W=np.sum([len(word) for word in corpus]) # the number of the total words\n",
    "    N=len(corpus)                            # the number of documents \n",
    "    topic=[[] for t in range(T)]\n",
    "    topic_num=np.zeros(T)    \n",
    "\n",
    "    for i,di in enumerate(corpus):\n",
    "        for wi in di:\n",
    "            p=np.zeros(T)\n",
    "            for j in range(T):\n",
    "                nij_wi=topic[j].count(wi)   # number of wi tht assigned to topic j\n",
    "                nij=len(topic[j])           # total number of words assigned to topic j \n",
    "                nij_di=np.sum(np.isin(topic[j],di)) # number of words from di in topic j\n",
    "                ni_di=len(di)               # total number of words in di\n",
    "                part1=(nij_wi+beta)/(nij+W*beta)\n",
    "                part2=(nij_di+alpha)/(ni_di+T*alpha)\n",
    "                p[j]=part1 * part2\n",
    "            pp=p/np.sum(p)\n",
    "            w_assign=np.random.multinomial(1, pp, size=1)\n",
    "            i_topic=int(np.where(w_assign[0]==1)[0])\n",
    "            topic[i_topic].append(wi)\n",
    "            topic_num=topic_num+w_assign\n",
    "    return(topic,topic_num)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 333,
   "metadata": {},
   "outputs": [],
   "source": [
    "corpus=[['a'], ['123', 'ggtfdg'], ['dsgfgfd', 'ds'], ['ds', '66', 'yhhr']]\n",
    "T=2\n",
    "alpha=1\n",
    "beta=1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 334,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([['123', 'ggtfdg', 'ds', 'ds', '66', 'yhhr'], ['a', 'dsgfgfd']],\n",
       " array([[6., 2.]]))"
      ]
     },
     "execution_count": 334,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "Z(corpus, T, alpha, beta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.2 sample $c_m$ from the nCRP\n",
    "$$p(c_m | w, c_{-m}, z) \\propto p(w_m | c, w_{-m}, z)  p(c_m | c_{-m})$$\n",
    "\n",
    "The calculation of the $p(w_m | c, w_{-m},z)$ value based on the likelihood function: \n",
    "\n",
    "$$p(w_m | c, w_{-m},z) = \\prod_{l=1}^{L} (\\frac{\\Gamma (n_{c_{m,l,-m}}^{(\\cdot)}+W\\eta)}{\\prod_{\\omega} \\Gamma (n_{c_{m,l,-m}}^{(\\omega)}+\\eta)}\\frac{\\prod_{\\omega} \\Gamma(n_{c_{m,l,-m}}^{(\\omega)}+n_{c_{m,l,m}}^{(\\cdot)}+\\eta)}{\\Gamma(n_{c_{m,l,-m}}^{(\\cdot)}+ n_{c_{m,l,m}}^{(\\cdot)}  W\\eta)})$$\n",
    "\n",
    "where, "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 335,
   "metadata": {},
   "outputs": [],
   "source": [
    "def word_likelihood(corpus,topic,eta):\n",
    "    \"\"\"\n",
    "    Description\n",
    "    ---------\n",
    "    Funcion:  calculation of p(w|c,w,z), based on the likelihood function\n",
    "    \n",
    "    Parameter\n",
    "    ---------\n",
    "    corpus: the total corpus, a list of documents, that is, a list of lists\n",
    "    topic: the topics of the corpus\n",
    "    eta: parameter \n",
    "    \n",
    "    Return\n",
    "    ------\n",
    "    a matrix of probabilities: \n",
    "        the number of rows = the number of documents, \n",
    "        the number of columns = the number of topics,\n",
    "        the cell: the probability of each document to be assigned in each topic\n",
    "    \"\"\"\n",
    "    \n",
    "    import math\n",
    "    res=np.zeros((len(corpus),len(topic)))  # generate the results matrix\n",
    "    \n",
    "    word_list=[]                            # generate the word list that contains all the words\n",
    "    for i in range(len(corpus)):\n",
    "        word_list=word_list+corpus[i]\n",
    "    W=len(word_list)                        # the length of word list\n",
    "    \n",
    "    for i,di in enumerate(corpus):\n",
    "        p_w=1\n",
    "        for j in range(len(topic)):         #calculate the tow parts of the equation\n",
    "            nc_dot=len(topic[j])    \n",
    "            part1_denominator=1\n",
    "            part2_nominator=1\n",
    "        \n",
    "            part1_nominator = math.gamma(nc_dot-np.sum(np.isin(topic[j],di))+W*eta)\n",
    "            part2_denominator = math.gamma(nc_dot+W*eta)\n",
    "        \n",
    "            for word in word_list:\n",
    "                ncm_w=topic[j].count(word)-di.count(word)\n",
    "                if ncm_w <0:\n",
    "                    ncm_w=0\n",
    "                nc_w=topic[j].count(word)\n",
    "                part1_denominator=part1_denominator*(ncm_w+eta)\n",
    "                part2_nominator=part2_nominator*(nc_w+eta)\n",
    "        \n",
    "            p_w=p_w*part1_nominator*part2_nominator/(part1_denominator*part2_denominator) \n",
    "            res[i,j]=p_w\n",
    "    res=res/np.sum(res,axis=1).reshape(-1,1)\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 344,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.85714286, 0.14285714],\n",
       "       [0.5       , 0.5       ],\n",
       "       [0.99660249, 0.00339751],\n",
       "       [0.99660249, 0.00339751]])"
      ]
     },
     "execution_count": 344,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus=[['a'], ['123', 'ggtfdg'], ['dsgfgfd', 'ds'], ['ds', '66', 'yhhr']]\n",
    "T=2\n",
    "alpha=1\n",
    "beta=1\n",
    "eta=1\n",
    "topic=Z(corpus, T, alpha, beta)[0]\n",
    "word_likelihood(corpus,topic,eta)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4.2.3 sample the  $p(c_m|c_{-m})$"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 114,
   "metadata": {},
   "outputs": [],
   "source": [
    "def CRP_prior(corpus,topic,alpha):\n",
    "    res=np.zeros((len(corpus),len(topic)))\n",
    "    for i,corpus_i in enumerate(corpus):\n",
    "        topic_new=[]\n",
    "        for t in topic:\n",
    "            topic_new.append([k for k in t if k not in corpus_i])\n",
    "        p=CRP_next(alpha,topic_new)\n",
    "        res[i,:]=p[1:]\n",
    "    return(res)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 345,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "array([[0.5       , 0.125     ],\n",
       "       [0.71428571, 0.14285714],\n",
       "       [0.33333333, 0.16666667],\n",
       "       [0.4       , 0.2       ]])"
      ]
     },
     "execution_count": 345,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus=[['a'], ['123', 'ggtfdg'], ['dsgfgfd', 'ds'], ['ds', '66', 'yhhr']]\n",
    "T=2\n",
    "alpha=1\n",
    "beta=1\n",
    "eta=1\n",
    "topic=Z(corpus, T, alpha, beta)[0]\n",
    "\n",
    "CRP_prior(corpus,topic,alpha)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### 4 function to combine the previous functions "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 193,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_position(corpus,T,alpha,beta,eta,iters=100):\n",
    "    word_list=[]\n",
    "    for i in corpus:\n",
    "        word_list=word_list+i\n",
    "    W=len(word_list)\n",
    "    gibbs=np.zeros((W,iters))\n",
    "    for j in range(iters):\n",
    "        topic=Z(corpus, T, alpha, beta)[0]\n",
    "        w_m=word_likelihood(corpus,topic,eta)\n",
    "        c_=CRP_prior(corpus,topic,alpha)\n",
    "        c_m = (w_m * c_) / (w_m * c_).sum(axis = 1)[:, np.newaxis]\n",
    "        g=[]\n",
    "        for i,corpus_i in enumerate(corpus):\n",
    "            for word in corpus_i:\n",
    "                g.append(int(np.where(np.random.multinomial(1, c_m[i])!=0)[0]))\n",
    "        gibbs[:,j]=g\n",
    "    \n",
    "    word_topic=[]\n",
    "    for i in range(W):\n",
    "        counts=[]\n",
    "        for t in range(T):\n",
    "            counts.append(list(gibbs[i]).count(t))\n",
    "        word_topic.append(np.where(counts==np.max(counts))[0][0])\n",
    "    return(word_topic)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 311,
   "metadata": {},
   "outputs": [],
   "source": [
    "def gibbs_list(corpus,T,alpha,beta,eta,iters):\n",
    "    word_list=[]\n",
    "    for i in corpus:\n",
    "        word_list=word_list+i\n",
    "    position=gibbs1(corpus,T,alpha,beta,eta,iters)\n",
    "    n_topic=len(np.unique(position))\n",
    "    word_list_topic=[[] for x in range(n_topic)]\n",
    "    for n_t in range(n_topic):\n",
    "        word_list_topic[n_t].append(list(np.array(word_list)[np.array(position)==np.array(n_t)]))\n",
    "    return(position,word_list_topic)    "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example **"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 348,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[[['a', 'dsgfgfd', 'ds']], [['123', 'ggtfdg', 'ds', '66', 'yhhr']]]"
      ]
     },
     "execution_count": 348,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "corpus=[['a'], ['123', 'ggtfdg'], ['dsgfgfd', 'ds'], ['ds', '66', 'yhhr']]\n",
    "T=2\n",
    "alpha=1\n",
    "beta=1\n",
    "eta=0.1\n",
    "iters=100\n",
    "\n",
    "gibbs_list(corpus,T,alpha,beta,eta,iters)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Wrap up to our *hLDA* function"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 358,
   "metadata": {},
   "outputs": [],
   "source": [
    "def node_sampling(corpus, alpha):\n",
    "    topic = []    \n",
    "    for corpus_i in corpus:\n",
    "        for word in corpus_i:\n",
    "            c_m = CRP_next(alpha,topic)\n",
    "            theta = np.random.multinomial(1, (np.array(c_m)/sum(c_m))).argmax()\n",
    "\n",
    "            if theta == len(c_m)-1:\n",
    "                topic.append([word])\n",
    "            else:\n",
    "                topic[theta].append(word)\n",
    "    return topic"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Example**"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 361,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[['a', 'dsgfgfd', 'ds'], ['123', 'ds', '66'], ['ggtfdg', 'yhhr']]"
      ]
     },
     "execution_count": 361,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "phi=2\n",
    "topic = node_sampling(corpus, phi)\n",
    "topic"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 390,
   "metadata": {},
   "outputs": [],
   "source": [
    "def hLDA(corpus, alpha, beta, eta, iters, level):\n",
    "    topic = node_sampling(corpus, phi)\n",
    "\n",
    "    hLDA_tree = [[] for _ in range(level)]\n",
    "    tmp_tree = []\n",
    "    node = [[] for _ in range(level+1)]\n",
    "    node[0].append(1)\n",
    "    \n",
    "    for i in range(level):\n",
    "        if i == 0:\n",
    "            wn_topic = gibbs_list(corpus, len(topic), alpha, beta, eta, iters)[1]\n",
    "            node_topic = [x for word in wn_topic for x in word]\n",
    "            hLDA_tree[0].append(node_topic)\n",
    "            tmp_tree.append(wn_topic[1:])\n",
    "            tmp_tree = tmp_tree[0]\n",
    "            node[1].append(len(wn_topic[1:]))\n",
    "        else:\n",
    "            for j in range(sum(node[i])):\n",
    "                if tmp_tree == []:\n",
    "                    break\n",
    "                wn_topic = gibbs_list(corpus, len(topic), alpha, beta, eta, iters)[1]\n",
    "                node_topic = [x for word in wn_topic for x in word]\n",
    "                hLDA_tree[i].append(node_topic)\n",
    "                tmp_tree.remove(tmp_tree[0])\n",
    "                if wn_topic[1:] != []:\n",
    "                    tmp_tree.extend(wn_topic[1:])\n",
    "                node[i+1].append(len(wn_topic[1:]))\n",
    "        \n",
    "    return hLDA_tree, node[:level]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 385,
   "metadata": {},
   "outputs": [],
   "source": [
    "wn_topic=gibbs_list(corpus, len(topic), alpha, beta, eta, iters)[1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 376,
   "metadata": {},
   "outputs": [],
   "source": [
    "alpha=0.1\n",
    "beta=0.1\n",
    "eta=0.1"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 391,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[[['ds'], ['dsgfgfd'], ['a', '123', 'ggtfdg', 'ds', '66', 'yhhr']]],\n",
       "  [[[]], [['dsgfgfd', 'ds'], []]]],\n",
       " [[1], [2]])"
      ]
     },
     "execution_count": 391,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hLDA(corpus, alpha, beta, eta, 100, 2)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "<span style=\"color:red\"> output 太丑了，得改.</span>\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 395,
   "metadata": {},
   "outputs": [],
   "source": [
    "trees=hLDA(corpus, alpha, beta, eta, 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 396,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[[['dsgfgfd'], ['a'], ['123', 'ggtfdg', 'ds', 'ds', '66', 'yhhr']]],\n",
       "  [[[], ['ds']], [[], ['ggtfdg']]]],\n",
       " [[1], [2]])"
      ]
     },
     "execution_count": 396,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "trees"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 323,
   "metadata": {},
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "from scipy.special import gammaln\n",
    "import random\n",
    "from collections import Counter\n",
    "import string\n",
    "import graphviz\n",
    "import pygraphviz\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 324,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Collecting pydot\n",
      "  Downloading https://files.pythonhosted.org/packages/c3/f1/e61d6dfe6c1768ed2529761a68f70939e2569da043e9f15a8d84bf56cadf/pydot-1.2.4.tar.gz (132kB)\n",
      "\u001b[K    100% |████████████████████████████████| 133kB 4.8MB/s ta 0:00:01\n",
      "\u001b[?25hRequirement already satisfied: pyparsing>=2.1.4 in /opt/conda/lib/python3.6/site-packages (from pydot)\n",
      "Building wheels for collected packages: pydot\n",
      "  Running setup.py bdist_wheel for pydot ... \u001b[?25ldone\n",
      "\u001b[?25h  Stored in directory: /home/jovyan/.cache/pip/wheels/6a/a5/14/25541ebcdeaf97a37b6d05c7ff15f5bd20f5e91b99d313e5b4\n",
      "Successfully built pydot\n",
      "Installing collected packages: pydot\n",
      "Successfully installed pydot-1.2.4\n",
      "\u001b[33mYou are using pip version 9.0.1, however version 10.0.0 is available.\n",
      "You should consider upgrading via the 'pip install --upgrade pip' command.\u001b[0m\n"
     ]
    }
   ],
   "source": [
    "! pip install pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 325,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pydot"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 327,
   "metadata": {},
   "outputs": [],
   "source": [
    "most_common = lambda x: Counter(x).most_common(1)[0][0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 393,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "([[[[], []]], [[[], ['dsgfgfd', 'ds']]]], [[1], [1]])"
      ]
     },
     "execution_count": 393,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "hLDA(corpus, alpha, beta, eta, 100, 2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 397,
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "unhashable type: 'list'",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0mTraceback (most recent call last)",
      "\u001b[0;32m<ipython-input-397-c0ef0a7b67ff>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[0;32m----> 1\u001b[0;31m \u001b[0mHLDA_plot\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mtrees\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mLen\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;36m8\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0msave\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-326-0a5f3bc5274b>\u001b[0m in \u001b[0;36mHLDA_plot\u001b[0;34m(hLDA_object, Len, save)\u001b[0m\n\u001b[1;32m     20\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     21\u001b[0m         \u001b[0;32mfor\u001b[0m \u001b[0mlen_root\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 22\u001b[0;31m             \u001b[0mroot_word\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;34m'\\n'\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mjoin\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mx\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;36m0\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mx\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mCounter\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mword\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen_root\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mmost_common\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mLen\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     23\u001b[0m             \u001b[0mleaf_index\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mleaf_struc\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen_root\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     24\u001b[0m             \u001b[0mstart\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mend_leaf_index\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mlen_root\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36m__init__\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    533\u001b[0m             \u001b[0;32mraise\u001b[0m \u001b[0mTypeError\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'expected at most 1 arguments, got %d'\u001b[0m \u001b[0;34m%\u001b[0m \u001b[0mlen\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    534\u001b[0m         \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m__init__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 535\u001b[0;31m         \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    536\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    537\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m__missing__\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mkey\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/opt/conda/lib/python3.6/collections/__init__.py\u001b[0m in \u001b[0;36mupdate\u001b[0;34m(*args, **kwds)\u001b[0m\n\u001b[1;32m    620\u001b[0m                     \u001b[0msuper\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mCounter\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;31m# fast path when counter is empty\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    621\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 622\u001b[0;31m                 \u001b[0m_count_elements\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0miterable\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    623\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mkwds\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    624\u001b[0m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mupdate\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mkwds\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mTypeError\u001b[0m: unhashable type: 'list'"
     ]
    }
   ],
   "source": [
    "HLDA_plot(trees, Len = 8, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 328,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2\n"
     ]
    },
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<IPython.core.display.Image object>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "HLDA_plot(hLDA(corpus, alpha, beta, eta, 100, 2), Len = 8, save = False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 326,
   "metadata": {},
   "outputs": [],
   "source": [
    "def HLDA_plot(hLDA_object, Len = 8, save = False):\n",
    "    \n",
    "    from IPython.display import Image, display\n",
    "    def viewPydot(pdot):\n",
    "        plt = Image(pdot.create_png())\n",
    "        display(plt)\n",
    "\n",
    "    words = hLDA_object[0]\n",
    "    struc = hLDA_object[1]\n",
    "      \n",
    "    graph = pydot.Dot(graph_type='graph')\n",
    "    end_index = [np.insert(np.cumsum(i),0,0) for i in struc]\n",
    "    \n",
    "    for level in range(len(struc)-1):\n",
    "        leaf_level = level + 1\n",
    "        leaf_word = words[leaf_level]\n",
    "        leaf_struc = struc[leaf_level]\n",
    "        word = words[level]\n",
    "        end_leaf_index = end_index[leaf_level]\n",
    "\n",
    "        for len_root in range(len(word)):\n",
    "            root_word = '\\n'.join([x[0] for x in Counter(word[len_root]).most_common(Len)])\n",
    "            leaf_index = leaf_struc[len_root]  \n",
    "            start = end_leaf_index[len_root]\n",
    "            end = end_leaf_index[len_root+1]\n",
    "            lf = leaf_word[start:end]  \n",
    "            for l in lf:\n",
    "                leaf_w = '\\n'.join([x[0] for x in Counter(list(l)).most_common(Len)])\n",
    "                edge = pydot.Edge(root_word, leaf_w)\n",
    "                graph.add_edge(edge)\n",
    "    if save == True:\n",
    "        graph.write_png('graph.png')\n",
    "    viewPydot(graph)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 5. Example"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 6.Optimization\n",
    "\n",
    "To make things faster"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "I think the easiest way to do optimization is :\n",
    "1. Use of vectorization\n",
    "2. JIT or AOT compilation of critical functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## 7. Install our package  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "The CRP is amenable to mixture modeling because we can establish a one-to-one rela- tionship between tables and mixture components and a one-to-many relationship between mixture components and data. In the models that we will consider, however, each data point is associated with multiple mixture components which lie along a path in a hierarchy. We develop a hierarchical version of the CRP to use in specifying a prior for such models.\n",
    "A nested Chinese restaurant process can be defined by imagining the following scenario. Suppose that there are an infinite number of infinite-table Chinese restaurants in a city. One restaurant is determined to be the root restaurant and on each of its infinite tables is a card with the name of another restaurant. On each of the tables in those restaurants are cards that refer to other restaurants, and this structure repeats infinitely. Each restaurant is referred to exactly once; thus, the restaurants in the city are organized into an infinitely-branched tree. Note that each restaurant is associated with a level in this tree (e.g., the root restaurant is at level 1 and the restaurants it refers to are at level 2).\n",
    "A tourist arrives in the city for a culinary vacation. On the first evening, he enters the root Chinese restaurant and selects a table using Eq. (1). On the second evening, he goes to the restaurant identified on the first night’s table and chooses another table, again from Eq. (1). He repeats this process for L days. At the end of the trip, the tourist has sat at L restaurants which constitute a path from the root to a restaurant at the Lth level in the infinite tree described above. After M tourists take L-day vacations, the collection of paths describe a particular L-level subtree of the infinite tree (see Figure 1a for an example of such a tree).\n",
    "This prior can be used to model topic hierarchies. Just as a standard CRP can be used to express uncertainty about a possible number of components, the nested CRP can be used to express uncertainty about possible L-level trees."
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
